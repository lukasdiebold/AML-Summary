\documentclass{article}

% Language setting
\usepackage[english]{babel}

% Set page size and margins
\usepackage[a4paper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

% Useful packages
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{tikz}
\usetikzlibrary{positioning}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage{algpseudocode}
\usepackage{algorithm}

% Shaded derivation blocks
\usepackage{xcolor}
\usepackage{framed}
\definecolor{shadecolor}{gray}{0.95}
\newenvironment{derivation}{\begin{snugshade}\noindent\textit{Derivation.}\ }{\end{snugshade}}
\newenvironment{notebox}{\begin{snugshade}\noindent\textit{Note.}\ }{\end{snugshade}}
\newtheorem{definition}{Definition}


\setlength{\parindent}{0pt}
\setlength{\parskip}{0.5em}

\title{AML Summary}
\author{Lukas Diebold}

\begin{document}
\begin{titlepage}
    \centering
    {\Huge AML Summary\par}
    \vspace{0.5cm}
    {\Large Advanced Machine Learning Lecture at ETH\par}
    \vspace{2cm}
    {\large Lukas Diebold\par}
    \vfill
    {\large \today\par}
\end{titlepage}

\section*{Disclaimer}
These notes are based on the Advanced Machine Learning lecture at ETH. They are
provided without guarantees regarding correctness or completeness. Some images
are adapted from or taken directly from lecture slides and remain the property of
their respective owners. This document is intended for educational use.

\section*{Help Improve These Notes}
Feedback and contributions are welcome. If you spot mistakes, unclear passages,
or missing intuition, please reach out or open an issue so the notes can be
improved for everyone.

\newpage

\tableofcontents
\newpage

\include{00 Math Preliminaries}
\include{01 Conceptual Foundation}
\include{02 Fundamentals of Machine Learning}
\include{03 Regression}
\include{04 Representations}
\include{05 Gaussian Processes for Regression}
\include{06 Ensemble Methods}
\include{07 Convex Optimization}
\include{08 Support Vector Machines}
\include{09 Neural Networks}
\include{10 Transformers}
\include{11 Graph Neural Networks}
\include{12 Anomaly Detection}
\include{13 Reinforcement Learning}
\include{14 Active Learning}
\include{15 Counterfactual Invariance}
\include{16 Variational Autoencoders}
\include{17 Non-parametric Bayesian Methods}
\include{18 Probably Approximately Correct Learning}

%\bibliographystyle{alpha}
%\bibliography{sample}

\end{document}
